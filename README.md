# Проект парсинга pep
Этот инструмент разработан для извлечения информации о документах Python Enhancement Proposals (PEP) и подсчёта количества документов, распределенных по различным статусам.

### Используемые технологии:
+ Python для написания кода
+ Scrapy для создания парсера

### Как запустить проект:

Для начала, клонируйте репозиторий и перейдите в его директорию:
```
git clone https://github.com/Ponimon4ik/scrapy_parser_pep
```
```
cd scrapy_parser_pep
```

Создайте и активируйте виртуальное окружение Python:

```
python3 -m venv env
```
```
source env/bin/activate
```

Затем установите необходимые зависимости, перечисленные в файле requirements.txt:

```
python3 -m pip install --upgrade pip
```
```
pip install -r requirements.txt
```

### Использование парсера:

Парсер формирует два .csv файла с результатами:
+ Первый файл включает список всех PEP, включая их номера, названия и статусы.
+ Второй файл содержит сводную информацию по статусам PEP, указывая количество документов для каждого статуса (статус, количество)

Чтобы запустить парсер, выполните следующую команду:


```
scrapy crawl pep 
```
Эта команда запустит парсинг документов PEP, подсчитает количество PEP в каждом статусе и сохранит результаты в папку "results".

### Разработчик:
+ Косолапов Константин - [kokos02r2](https://github.com/kokos02r2)